{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167623dd",
   "metadata": {},
   "source": [
    "# Notebook 1 – Extract & Transform \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7750c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d381605",
   "metadata": {},
   "source": [
    "## Extracting and Inspecting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f84473b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>payment_mode</th>\n",
       "      <th>location</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T03512</td>\n",
       "      <td>U039</td>\n",
       "      <td>December 22 2021</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>998</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Paid electricity bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T03261</td>\n",
       "      <td>U179</td>\n",
       "      <td>03/24/2022</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Food</td>\n",
       "      <td>$143</td>\n",
       "      <td>Card</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Grocery shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T04316</td>\n",
       "      <td>U143</td>\n",
       "      <td>October 18 2022</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>149</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T05649</td>\n",
       "      <td>U079</td>\n",
       "      <td>12/12/2021</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>49</td>\n",
       "      <td>UPI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paid electricity bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T14750</td>\n",
       "      <td>U020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Income</td>\n",
       "      <td>Other Income</td>\n",
       "      <td>83,802</td>\n",
       "      <td>Bank Transfer</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Gift via app</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id user_id              date transaction_type      category  \\\n",
       "0         T03512    U039  December 22 2021          Expense          Rent   \n",
       "1         T03261    U179        03/24/2022          Expense          Food   \n",
       "2         T04316    U143   October 18 2022          Expense          Rent   \n",
       "3         T05649    U079        12/12/2021          Expense          Rent   \n",
       "4         T14750    U020               NaN           Income  Other Income   \n",
       "\n",
       "   amount   payment_mode   location                   notes  \n",
       "0     998           Cash       Pune  Paid electricity bill   \n",
       "1    $143           Card      Delhi        Grocery shopping  \n",
       "2     149           Cash  Bengaluru                     NaN  \n",
       "3      49            UPI        NaN   Paid electricity bill  \n",
       "4  83,802  Bank Transfer    Chennai            Gift via app  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_path = \"/Users/nathanomenge/Desktop/Projects/Learning/DataMining_GroupProject/data/raw/budgetwise_synthetic_dirty_raw.csv\"\n",
    "\n",
    "df_raw = pd.read_csv(raw_path)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503d010",
   "metadata": {},
   "source": [
    "## Inspecting the Data\n",
    "### Shape and Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789aa8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15836, 9),\n",
       " Index(['transaction_id', 'user_id', 'date', 'transaction_type', 'category',\n",
       "        'amount', 'payment_mode', 'location', 'notes'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape, df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc1594",
   "metadata": {},
   "source": [
    "### Data types & non-null counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd2394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15836 entries, 0 to 15835\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   transaction_id    15836 non-null  object\n",
      " 1   user_id           15836 non-null  object\n",
      " 2   date              15492 non-null  object\n",
      " 3   transaction_type  15836 non-null  object\n",
      " 4   category          15678 non-null  object\n",
      " 5   amount            15658 non-null  object\n",
      " 6   payment_mode      15333 non-null  object\n",
      " 7   location          15114 non-null  object\n",
      " 8   notes             14302 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8b080",
   "metadata": {},
   "source": [
    "### Preview rows (At random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf138d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>payment_mode</th>\n",
       "      <th>location</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>T13747</td>\n",
       "      <td>U140</td>\n",
       "      <td>21-01-20</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Food</td>\n",
       "      <td>$199</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Lucknow</td>\n",
       "      <td>Paid electricity bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>T02374</td>\n",
       "      <td>U089</td>\n",
       "      <td>06/02/2020</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>106</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Doctor visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>T04501</td>\n",
       "      <td>U001</td>\n",
       "      <td>September 15 2021</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>₹1,017</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Netflix subscription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>T00737</td>\n",
       "      <td>U093</td>\n",
       "      <td>10/13/2020</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>455</td>\n",
       "      <td>Cash</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5771</th>\n",
       "      <td>T03866</td>\n",
       "      <td>U088</td>\n",
       "      <td>16-12-21</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>449</td>\n",
       "      <td>UPI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paid electricity bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8494</th>\n",
       "      <td>T12657</td>\n",
       "      <td>U013</td>\n",
       "      <td>06/17/2019</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>300</td>\n",
       "      <td>Card</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Netflix subscription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14961</th>\n",
       "      <td>T02693</td>\n",
       "      <td>U072</td>\n",
       "      <td>08-08-20</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Others</td>\n",
       "      <td>297</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Dinner at resto cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>T10026</td>\n",
       "      <td>U165</td>\n",
       "      <td>27-06-22</td>\n",
       "      <td>Income</td>\n",
       "      <td>Salary</td>\n",
       "      <td>62,768</td>\n",
       "      <td>Card</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Monthly rent via app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>T11740</td>\n",
       "      <td>U083</td>\n",
       "      <td>05/20/2021</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Food</td>\n",
       "      <td>1,766</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Grocery shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>T13009</td>\n",
       "      <td>U077</td>\n",
       "      <td>February 02 2020</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>₹818</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Paid electricity bill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id user_id               date transaction_type  \\\n",
       "13342         T13747    U140           21-01-20          Expense   \n",
       "169           T02374    U089         06/02/2020          Expense   \n",
       "2099          T04501    U001  September 15 2021          Expense   \n",
       "4948          T00737    U093         10/13/2020          Expense   \n",
       "5771          T03866    U088           16-12-21          Expense   \n",
       "8494          T12657    U013         06/17/2019          Expense   \n",
       "14961         T02693    U072           08-08-20          Expense   \n",
       "8035          T10026    U165           27-06-22           Income   \n",
       "88            T11740    U083         05/20/2021          Expense   \n",
       "12179         T13009    U077   February 02 2020          Expense   \n",
       "\n",
       "            category  amount payment_mode   location                   notes  \n",
       "13342           Food    $199          UPI    Lucknow   Paid electricity bill  \n",
       "169             Rent     106          UPI       Pune            Doctor visit  \n",
       "2099            Rent  ₹1,017         Cash     Jaipur    Netflix subscription  \n",
       "4948            Rent     455         Cash     MUMBAI                     NaN  \n",
       "5771            Rent     449          UPI        NaN  Paid electricity bill   \n",
       "8494   Entertainment     300         Card       Pune    Netflix subscription  \n",
       "14961         Others     297          UPI  Ahmedabad    Dinner at resto cash  \n",
       "8035          Salary  62,768         Card     Jaipur    Monthly rent via app  \n",
       "88              Food   1,766         Cash    Chennai        Grocery shopping  \n",
       "12179           Rent    ₹818          UPI  Bengaluru   Paid electricity bill  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f9784",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2023be86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "notes               1534\n",
       "location             722\n",
       "payment_mode         503\n",
       "date                 344\n",
       "amount               178\n",
       "category             158\n",
       "transaction_id         0\n",
       "user_id                0\n",
       "transaction_type       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d11c4",
   "metadata": {},
   "source": [
    "### Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1aaa1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_type      2\n",
       "category            212\n",
       "payment_mode         62\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[['transaction_type', 'category', 'payment_mode']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c734df",
   "metadata": {},
   "source": [
    "## Data Audit Summary\n",
    "\n",
    "The dataset contains **15,836 rows** and **9 columns**, representing individual financial transactions across multiple users. All columns are stored as `object` type at this stage, which is expected before cleaning.\n",
    "\n",
    "### Missing Data Overview\n",
    "A preliminary inspection shows varying levels of missing values:\n",
    "\n",
    "- **notes:** 1,534 missing  \n",
    "- **location:** 722 missing  \n",
    "- **payment_mode:** 503 missing  \n",
    "- **date:** 344 missing  \n",
    "- **amount:** 178 missing  \n",
    "- **category:** 158 missing  \n",
    "- `transaction_id`, `user_id`, and `transaction_type` have no missing values.\n",
    "\n",
    "This pattern suggests that the dataset is moderately messy, with missing contextual fields such as location and notes, and some critical analytical fields (\"date\" and \"amount\") that must be cleaned.\n",
    "\n",
    "### Data Type Issues\n",
    "All columns are currently of type `object`, which is typical for raw CSV data. However:\n",
    "\n",
    "- **date** contains a mixture of formats (e.g., `\"September 15 2021\"`, `\"21-01-20\"`, `\"06/02/2020\"`, `\"16-12-21\"`), meaning a custom multi-format parser will be required.\n",
    "- **amount** values contain mixed formatting such as currency symbols (`₹`, `$`), commas (`\"62,768\"`), and plain numbers (`\"998\"`). These must be cleaned and converted to numeric.\n",
    "- **payment_mode** and **category** show inconsistent levels of granularity and capitalization.\n",
    "\n",
    "### Unique Value Checks\n",
    "- **transaction_type:** 2 values (`Income`, `Expense`) – consistent.\n",
    "- **category:** 212 unique categories – unusually high, suggesting inconsistent labeling.\n",
    "- **payment_mode:** 62 unique values – indicates mixed formatting and possible misspellings.\n",
    "\n",
    "### Key Findings\n",
    "- The dataset requires **significant transformation**, especially in the `date`, `amount`, `category`, and `payment_mode` fields.\n",
    "- The structural integrity is good (no missing user or transaction IDs).\n",
    "- After cleaning, this dataset will be suitable for analysis such as spending trends, category insights, and user-level financial behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8eea8d",
   "metadata": {},
   "source": [
    "## Transform Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87a605",
   "metadata": {},
   "source": [
    "### Parsing Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358d4d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/410yfyf16jl9_7z_msy08s900000gn/T/ipykernel_89400/3125422801.py:4: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  return pd.to_datetime(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>December 22 2021</td>\n",
       "      <td>2021-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/24/2022</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>October 18 2022</td>\n",
       "      <td>2022-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/12/2021</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12-07-22</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>September 12 2019</td>\n",
       "      <td>2019-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04-11-22</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>February 03 2021</td>\n",
       "      <td>2021-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>02-11-22</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11/21/2022</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>March 03 2021</td>\n",
       "      <td>2021-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>January 20 2022</td>\n",
       "      <td>2022-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>03/08/2022</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date date_parsed\n",
       "0    December 22 2021  2021-12-22\n",
       "1          03/24/2022         NaT\n",
       "2     October 18 2022  2022-10-18\n",
       "3          12/12/2021         NaT\n",
       "4                 NaN         NaT\n",
       "5            12-07-22         NaT\n",
       "6   September 12 2019  2019-09-12\n",
       "7          2022-01-06         NaT\n",
       "8            04-11-22         NaT\n",
       "9    February 03 2021  2021-02-03\n",
       "10           02-11-22         NaT\n",
       "11         11/21/2022         NaT\n",
       "12         12/29/2022         NaT\n",
       "13         2020-10-26         NaT\n",
       "14         2021-05-25         NaT\n",
       "15      March 03 2021  2021-03-03\n",
       "16         2021-09-24         NaT\n",
       "17         2022-07-02         NaT\n",
       "18    January 20 2022  2022-01-20\n",
       "19         03/08/2022         NaT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  First-pass date parsing\n",
    "\n",
    "def parse_dates(series):\n",
    "    return pd.to_datetime(\n",
    "        series,\n",
    "        errors='coerce',\n",
    "        infer_datetime_format=True\n",
    "    )\n",
    "\n",
    "df_raw['date_parsed'] = parse_dates(df_raw['date'])\n",
    "\n",
    "df_raw[['date', 'date_parsed']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8256ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(13486)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying how many dates failed to parse\n",
    "df_raw['date_parsed'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6325aca",
   "metadata": {},
   "source": [
    "### Date Parsing Attempt 1 – Results\n",
    "\n",
    "The first parsing attempt using `pd.to_datetime(..., infer_datetime_format=True)` succeeded only on long-form dates such as:\n",
    "\n",
    "- \"December 22 2021\"\n",
    "- \"October 18 2022\"\n",
    "- \"September 12 2019\"\n",
    "\n",
    "However, it failed on most numeric formats, including:\n",
    "\n",
    "- `MM/DD/YYYY` (e.g., \"03/24/2022\")\n",
    "- `DD/MM/YYYY` or `DD-MM-YY` (e.g., \"12-07-22\", \"21-01-20\")\n",
    "-  Short dates (e.g., \"2022-01-06\")\n",
    "\n",
    "Out of **15,836** records, **13,486** dates failed to parse on the first attempt. This confirms that the dataset includes multiple date patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdcad721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>December 22 2021</td>\n",
       "      <td>2021-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/24/2022</td>\n",
       "      <td>2022-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>October 18 2022</td>\n",
       "      <td>2022-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/12/2021</td>\n",
       "      <td>2021-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12-07-22</td>\n",
       "      <td>2022-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>September 12 2019</td>\n",
       "      <td>2019-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>2022-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04-11-22</td>\n",
       "      <td>2022-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>February 03 2021</td>\n",
       "      <td>2021-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>02-11-22</td>\n",
       "      <td>2022-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11/21/2022</td>\n",
       "      <td>2022-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>2022-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>2021-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>March 03 2021</td>\n",
       "      <td>2021-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>2022-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>January 20 2022</td>\n",
       "      <td>2022-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>03/08/2022</td>\n",
       "      <td>2022-03-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date date_parsed\n",
       "0    December 22 2021  2021-12-22\n",
       "1          03/24/2022  2022-03-24\n",
       "2     October 18 2022  2022-10-18\n",
       "3          12/12/2021  2021-12-12\n",
       "4                 NaN         NaT\n",
       "5            12-07-22  2022-07-12\n",
       "6   September 12 2019  2019-09-12\n",
       "7          2022-01-06  2022-01-06\n",
       "8            04-11-22  2022-11-04\n",
       "9    February 03 2021  2021-02-03\n",
       "10           02-11-22  2022-11-02\n",
       "11         11/21/2022  2022-11-21\n",
       "12         12/29/2022  2022-12-29\n",
       "13         2020-10-26  2020-10-26\n",
       "14         2021-05-25  2021-05-25\n",
       "15      March 03 2021  2021-03-03\n",
       "16         2021-09-24  2021-09-24\n",
       "17         2022-07-02  2022-07-02\n",
       "18    January 20 2022  2022-01-20\n",
       "19         03/08/2022  2022-03-08"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# A list of patterns we want to try manually\n",
    "date_formats = [\n",
    "    \"%m/%d/%Y\",  # 03/24/2022\n",
    "    \"%d/%m/%Y\",  # 24/03/2022\n",
    "    \"%Y-%m-%d\",  # 2022-01-06\n",
    "    \"%d-%m-%y\",  # 12-07-22\n",
    "    \"%d-%m-%Y\",  # 12-07-2022\n",
    "    \"%m-%d-%y\",  # 07-12-22\n",
    "]\n",
    "\n",
    "def parse_with_formats(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    \n",
    "    # Try each known format\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Apply the custom parser ONLY to rows where the first parser failed\n",
    "mask_failed = df_raw['date_parsed'].isna()\n",
    "\n",
    "df_raw.loc[mask_failed, 'date_parsed'] = df_raw.loc[mask_failed, 'date'].apply(parse_with_formats)\n",
    "\n",
    "df_raw[['date', 'date_parsed']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7re85m6u7hp",
   "metadata": {},
   "source": [
    "### Date Parsing Attempt 2 – Results\n",
    "\n",
    "The date parser now successfully handles the remaining numeric date formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eqf0qanbuzd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse after attempt 2: 381\n",
      "Successfully parsed: 15,455\n",
      "Success rate: 97.6%\n",
      "\n",
      "Remaining unparsed date patterns (36):\n",
      "['29/10/19' '2020/11/17' '2020/05/05' '2022/12/09' '28/09/22' '2020/02/20'\n",
      " '21/08/21' '11/02/22' '2021/02/16' '06/07/20']\n"
     ]
    }
   ],
   "source": [
    "# Check parsing improvement\n",
    "print(f\"Failed to parse after attempt 2: {df_raw['date_parsed'].isna().sum():,}\")\n",
    "print(f\"Successfully parsed: {(~df_raw['date_parsed'].isna()).sum():,}\")\n",
    "print(f\"Success rate: {((~df_raw['date_parsed'].isna()).sum() / len(df_raw)) * 100:.1f}%\")\n",
    "\n",
    "# Look at remaining unparsed dates\n",
    "remaining_unparsed = df_raw[df_raw['date_parsed'].isna() & df_raw['date'].notna()]['date'].unique()\n",
    "print(f\"\\nRemaining unparsed date patterns ({len(remaining_unparsed)}):\")\n",
    "print(remaining_unparsed[:10] if len(remaining_unparsed) > 0 else \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1yovwmm3w",
   "metadata": {},
   "source": [
    "### Cleaning Amount Values\n",
    "\n",
    "Now we need to handle the mixed currency formatting in the amount column. From our inspection, we saw values like `$143`, `₹1,017`, `62,768`, and plain numbers like `998`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57w7gwzr6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample amount values before cleaning:\n",
      "['124', '$406', '410', '267', '231', '1,610', '314', '1,554', '891', '$323', '846', '71', '393', '653', '₹409', '2,883', '447', '247', '1,517', '1,434']\n",
      "\n",
      "Amount cleaning results:\n",
      "Original non-null amounts: 15,658\n",
      "Successfully cleaned amounts: 15,658\n",
      "Failed to clean: 0\n",
      "\n",
      "Amount statistics after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     15658.000000\n",
       "mean      12477.195491\n",
       "std       56249.380633\n",
       "min       -1313.000000\n",
       "25%         203.000000\n",
       "50%         534.000000\n",
       "75%        1742.000000\n",
       "max      999999.000000\n",
       "Name: amount_cleaned, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine unique amount patterns before cleaning\n",
    "print(\"Sample amount values before cleaning:\")\n",
    "print(df_raw['amount'].dropna().sample(20, random_state=42).tolist())\n",
    "\n",
    "# Function to clean amount values\n",
    "def clean_amount(amount_str):\n",
    "    if pd.isna(amount_str):\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and remove currency symbols and commas\n",
    "    cleaned = str(amount_str).replace('₹', '').replace('$', '').replace(',', '').strip()\n",
    "    \n",
    "    try:\n",
    "        return float(cleaned)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply cleaning\n",
    "df_raw['amount_cleaned'] = df_raw['amount'].apply(clean_amount)\n",
    "\n",
    "print(f\"\\nAmount cleaning results:\")\n",
    "print(f\"Original non-null amounts: {df_raw['amount'].notna().sum():,}\")\n",
    "print(f\"Successfully cleaned amounts: {df_raw['amount_cleaned'].notna().sum():,}\")\n",
    "print(f\"Failed to clean: {(df_raw['amount'].notna() & df_raw['amount_cleaned'].isna()).sum():,}\")\n",
    "\n",
    "# Check conversion results\n",
    "print(f\"\\nAmount statistics after cleaning:\")\n",
    "df_raw['amount_cleaned'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ykg392e0p",
   "metadata": {},
   "source": [
    "### Cleaning Other Categorical Fields\n",
    "\n",
    " Standardizing the categorical fields that showed inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "t9997a3fuv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment mode values before cleaning:\n",
      "Unique values: 62\n",
      "payment_mode\n",
      "Bank Transfer    3838\n",
      "Cash             3787\n",
      "UPI              3736\n",
      "Card             3721\n",
      "UI                 15\n",
      "Csah               12\n",
      "Cah                11\n",
      "PUI                10\n",
      "UPPI                9\n",
      "UP                  9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Payment mode after cleaning:\n",
      "Unique values: 35\n",
      "payment_mode_cleaned\n",
      "Bank Transfer    3902\n",
      "Cash             3787\n",
      "UPI              3736\n",
      "Card             3721\n",
      "Unknown           503\n",
      "Ui                 15\n",
      "Csah               12\n",
      "Cah                11\n",
      "Pui                10\n",
      "Uppi                9\n",
      "Up                  9\n",
      "Uupi                8\n",
      "Pi                  8\n",
      "Car                 8\n",
      "Ash                 8\n",
      "Cassh               8\n",
      "Ard                 8\n",
      "Caard               7\n",
      "Crad                7\n",
      "Acsh                6\n",
      "Crd                 6\n",
      "Cadr                6\n",
      "Uip                 5\n",
      "Upii                5\n",
      "Cardd               4\n",
      "Csh                 4\n",
      "Cashh               4\n",
      "Carrd               3\n",
      "Acrd                3\n",
      "Ccash               3\n",
      "Cahs                3\n",
      "Cas                 2\n",
      "Cad                 2\n",
      "Caash               2\n",
      "Ccard               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Category values before cleaning:\n",
      "Unique values: 212\n",
      "category\n",
      "Food             3764\n",
      "Rent             3078\n",
      "Travel           1453\n",
      "Utilities        1298\n",
      "Entertainment    1079\n",
      "Other Income      749\n",
      "Bonus             743\n",
      "Salary            741\n",
      "Others            609\n",
      "Savings           575\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean payment_mode field\n",
    "print(\"Payment mode values before cleaning:\")\n",
    "print(f\"Unique values: {df_raw['payment_mode'].nunique()}\")\n",
    "print(df_raw['payment_mode'].value_counts().head(10))\n",
    "\n",
    "# Standardize payment modes\n",
    "def clean_payment_mode(mode):\n",
    "    if pd.isna(mode):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    mode = str(mode).strip().title()\n",
    "    \n",
    "    # Standardize variations\n",
    "    if 'bank' in mode.lower() or 'transfer' in mode.lower():\n",
    "        return 'Bank Transfer'\n",
    "    elif mode.lower() in ['upi', 'paytm', 'gpay', 'phonepe']:\n",
    "        return 'UPI'\n",
    "    elif mode.lower() in ['card', 'debit', 'credit']:\n",
    "        return 'Card' \n",
    "    elif mode.lower() == 'cash':\n",
    "        return 'Cash'\n",
    "    else:\n",
    "        return mode  # Keep other values as-is\n",
    "\n",
    "df_raw['payment_mode_cleaned'] = df_raw['payment_mode'].apply(clean_payment_mode)\n",
    "\n",
    "print(f\"\\nPayment mode after cleaning:\")\n",
    "print(f\"Unique values: {df_raw['payment_mode_cleaned'].nunique()}\")\n",
    "print(df_raw['payment_mode_cleaned'].value_counts())\n",
    "\n",
    "# Clean categories - group similar ones\n",
    "print(f\"\\n\\nCategory values before cleaning:\")\n",
    "print(f\"Unique values: {df_raw['category'].nunique()}\")\n",
    "print(df_raw['category'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ygibjomzbr",
   "metadata": {},
   "source": [
    "### Adding Calculated Fields (Feature Engineering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "euqvga90yk6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after removing missing amounts: (15658, 12)\n",
      "Calculated fields added:\n",
      "- user_transaction_frequency: Number of transactions per user\n",
      "- user_total_spending: Total amount spent per user\n",
      "- user_avg_transaction: Average transaction amount per user\n",
      "- user_expense_ratio: Ratio of expenses to total transactions per user\n",
      "- year, month, day_of_week, is_weekend: Temporal features\n",
      "- amount_category: Categorized transaction amounts\n",
      "Final dataset shape: (15658, 21)\n",
      "Final columns: ['transaction_id', 'user_id', 'date', 'transaction_type', 'category', 'amount', 'payment_mode', 'location', 'notes', 'date_parsed', 'amount_cleaned', 'payment_mode_cleaned', 'user_transaction_frequency', 'user_total_spending', 'user_avg_transaction', 'user_expense_ratio', 'year', 'month', 'day_of_week', 'is_weekend', 'amount_category']\n"
     ]
    }
   ],
   "source": [
    "# Create working dataframe with cleaned data for calculations\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# Replace original columns with cleaned versions\n",
    "df_clean['date'] = df_clean['date_parsed']\n",
    "df_clean['amount'] = df_clean['amount_cleaned'] \n",
    "df_clean['payment_mode'] = df_clean['payment_mode_cleaned']\n",
    "\n",
    "# Remove rows with missing critical data\n",
    "df_clean = df_clean.dropna(subset=['amount'])\n",
    "print(f\"Dataset after removing missing amounts: {df_clean.shape}\")\n",
    "\n",
    "# 1. Transaction frequency per user\n",
    "user_transaction_counts = df_clean.groupby('user_id')['transaction_id'].count()\n",
    "df_clean['user_transaction_frequency'] = df_clean['user_id'].map(user_transaction_counts)\n",
    "\n",
    "# 2. Total spending per user\n",
    "user_total_spending = df_clean.groupby('user_id')['amount'].sum()\n",
    "df_clean['user_total_spending'] = df_clean['user_id'].map(user_total_spending)\n",
    "\n",
    "# 3. Average transaction amount per user  \n",
    "user_avg_amount = df_clean.groupby('user_id')['amount'].mean()\n",
    "df_clean['user_avg_transaction'] = df_clean['user_id'].map(user_avg_amount)\n",
    "\n",
    "# 4. Expense ratio per user (expenses / total transactions)\n",
    "user_expense_counts = df_clean[df_clean['transaction_type'] == 'Expense'].groupby('user_id')['transaction_id'].count()\n",
    "df_clean['user_expense_ratio'] = df_clean['user_id'].map(user_expense_counts / user_transaction_counts).fillna(0)\n",
    "\n",
    "# 5. Add temporal features for valid dates\n",
    "df_clean['year'] = df_clean['date'].dt.year\n",
    "df_clean['month'] = df_clean['date'].dt.month\n",
    "df_clean['day_of_week'] = df_clean['date'].dt.dayofweek\n",
    "df_clean['is_weekend'] = df_clean['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# 6. Transaction amount categories\n",
    "df_clean['amount_category'] = pd.cut(df_clean['amount'], \n",
    "                                   bins=[0, 100, 500, 1000, 5000, float('inf')],\n",
    "                                   labels=['Small', 'Medium', 'Large', 'Very Large', 'Extreme'])\n",
    "\n",
    "print(\"Calculated fields added:\")\n",
    "print(\"- user_transaction_frequency: Number of transactions per user\")\n",
    "print(\"- user_total_spending: Total amount spent per user\") \n",
    "print(\"- user_avg_transaction: Average transaction amount per user\")\n",
    "print(\"- user_expense_ratio: Ratio of expenses to total transactions per user\")\n",
    "print(\"- year, month, day_of_week, is_weekend: Temporal features\")\n",
    "print(\"- amount_category: Categorized transaction amounts\")\n",
    "\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "print(f\"Final columns: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ky6sa79i",
   "metadata": {},
   "source": [
    "### Final Data Validation and Export\n",
    "\n",
    "Inspecting the cleaned dataset and exporting it for use in the later stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "uai8vpwz0j",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL DATASET VALIDATION ===\n",
      "Final shape: (15658, 21)\n",
      "Original raw dataset: (15836, 12)\n",
      "Data reduction: 1.1%\n",
      "Missing values in final dataset:\n",
      "notes              1523\n",
      "location            713\n",
      "date                376\n",
      "day_of_week         376\n",
      "month               376\n",
      "date_parsed         376\n",
      "year                376\n",
      "category            154\n",
      "amount_category      62\n",
      "dtype: int64\n",
      "Data types in final dataset:\n",
      "transaction_id                        object\n",
      "user_id                               object\n",
      "date                          datetime64[ns]\n",
      "transaction_type                      object\n",
      "category                              object\n",
      "amount                               float64\n",
      "payment_mode                          object\n",
      "location                              object\n",
      "notes                                 object\n",
      "date_parsed                   datetime64[ns]\n",
      "amount_cleaned                       float64\n",
      "payment_mode_cleaned                  object\n",
      "user_transaction_frequency             int64\n",
      "user_total_spending                  float64\n",
      "user_avg_transaction                 float64\n",
      "user_expense_ratio                   float64\n",
      "year                                 float64\n",
      "month                                float64\n",
      "day_of_week                          float64\n",
      "is_weekend                             int64\n",
      "amount_category                     category\n",
      "dtype: object\n",
      "Sample of final cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>payment_mode</th>\n",
       "      <th>location</th>\n",
       "      <th>notes</th>\n",
       "      <th>date_parsed</th>\n",
       "      <th>amount_cleaned</th>\n",
       "      <th>payment_mode_cleaned</th>\n",
       "      <th>user_transaction_frequency</th>\n",
       "      <th>user_total_spending</th>\n",
       "      <th>user_avg_transaction</th>\n",
       "      <th>user_expense_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>amount_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T03512</td>\n",
       "      <td>U039</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>998.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Paid electricity bill</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>998.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>86</td>\n",
       "      <td>1017618.0</td>\n",
       "      <td>11832.767442</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T03261</td>\n",
       "      <td>U179</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Food</td>\n",
       "      <td>143.0</td>\n",
       "      <td>Card</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Grocery shopping</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>143.0</td>\n",
       "      <td>Card</td>\n",
       "      <td>87</td>\n",
       "      <td>945163.0</td>\n",
       "      <td>10863.942529</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T04316</td>\n",
       "      <td>U143</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>90</td>\n",
       "      <td>876727.0</td>\n",
       "      <td>9741.411111</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T05649</td>\n",
       "      <td>U079</td>\n",
       "      <td>2021-12-12</td>\n",
       "      <td>Expense</td>\n",
       "      <td>Rent</td>\n",
       "      <td>49.0</td>\n",
       "      <td>UPI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paid electricity bill</td>\n",
       "      <td>2021-12-12</td>\n",
       "      <td>49.0</td>\n",
       "      <td>UPI</td>\n",
       "      <td>82</td>\n",
       "      <td>706444.0</td>\n",
       "      <td>8615.170732</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T14750</td>\n",
       "      <td>U020</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Income</td>\n",
       "      <td>Other Income</td>\n",
       "      <td>83802.0</td>\n",
       "      <td>Bank Transfer</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Gift via app</td>\n",
       "      <td>NaT</td>\n",
       "      <td>83802.0</td>\n",
       "      <td>Bank Transfer</td>\n",
       "      <td>101</td>\n",
       "      <td>1108349.0</td>\n",
       "      <td>10973.752475</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Extreme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id user_id       date transaction_type      category   amount  \\\n",
       "0         T03512    U039 2021-12-22          Expense          Rent    998.0   \n",
       "1         T03261    U179 2022-03-24          Expense          Food    143.0   \n",
       "2         T04316    U143 2022-10-18          Expense          Rent    149.0   \n",
       "3         T05649    U079 2021-12-12          Expense          Rent     49.0   \n",
       "4         T14750    U020        NaT           Income  Other Income  83802.0   \n",
       "\n",
       "    payment_mode   location                   notes date_parsed  \\\n",
       "0           Cash       Pune  Paid electricity bill   2021-12-22   \n",
       "1           Card      Delhi        Grocery shopping  2022-03-24   \n",
       "2           Cash  Bengaluru                     NaN  2022-10-18   \n",
       "3            UPI        NaN   Paid electricity bill  2021-12-12   \n",
       "4  Bank Transfer    Chennai            Gift via app         NaT   \n",
       "\n",
       "   amount_cleaned payment_mode_cleaned  user_transaction_frequency  \\\n",
       "0           998.0                 Cash                          86   \n",
       "1           143.0                 Card                          87   \n",
       "2           149.0                 Cash                          90   \n",
       "3            49.0                  UPI                          82   \n",
       "4         83802.0        Bank Transfer                         101   \n",
       "\n",
       "   user_total_spending  user_avg_transaction  user_expense_ratio    year  \\\n",
       "0            1017618.0          11832.767442            0.825581  2021.0   \n",
       "1             945163.0          10863.942529            0.839080  2022.0   \n",
       "2             876727.0           9741.411111            0.855556  2022.0   \n",
       "3             706444.0           8615.170732            0.853659  2021.0   \n",
       "4            1108349.0          10973.752475            0.831683     NaN   \n",
       "\n",
       "   month  day_of_week  is_weekend amount_category  \n",
       "0   12.0          2.0           0           Large  \n",
       "1    3.0          3.0           0          Medium  \n",
       "2   10.0          1.0           0          Medium  \n",
       "3   12.0          6.0           1           Small  \n",
       "4    NaN          NaN           0         Extreme  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final validation\n",
    "print(\"=== FINAL DATASET VALIDATION ===\")\n",
    "print(f\"Final shape: {df_clean.shape}\")\n",
    "print(f\"Original raw dataset: {df_raw.shape}\")\n",
    "print(f\"Data reduction: {((df_raw.shape[0] - df_clean.shape[0]) / df_raw.shape[0]) * 100:.1f}%\")\n",
    "\n",
    "print(\"Missing values in final dataset:\")\n",
    "missing_summary = df_clean.isnull().sum().sort_values(ascending=False)\n",
    "print(missing_summary[missing_summary > 0])\n",
    "\n",
    "print(\"Data types in final dataset:\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "print(\"Sample of final cleaned data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "kk9bxmztb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET EXPORTED ===\n",
      "Saved to: ../data/transformed/cleaned_dataset.csv\n",
      "Final dataset dimensions: (15658, 18)\n",
      "Columns exported: ['transaction_id', 'user_id', 'date', 'transaction_type', 'category', 'amount', 'payment_mode', 'location', 'notes', 'user_transaction_frequency', 'user_total_spending', 'user_avg_transaction', 'user_expense_ratio', 'year', 'month', 'day_of_week', 'is_weekend', 'amount_category']\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns for final export\n",
    "final_columns = [\n",
    "    'transaction_id', 'user_id', 'date', 'transaction_type', 'category', \n",
    "    'amount', 'payment_mode', 'location', 'notes',\n",
    "    'user_transaction_frequency', 'user_total_spending', 'user_avg_transaction', \n",
    "    'user_expense_ratio', 'year', 'month', 'day_of_week', 'is_weekend', \n",
    "    'amount_category'\n",
    "]\n",
    "\n",
    "df_final = df_clean[final_columns].copy()\n",
    "\n",
    "# Export to transformed data folder\n",
    "output_path = \"../data/transformed/cleaned_dataset.csv\"\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"=== DATASET EXPORTED ===\")\n",
    "print(f\"Saved to: {output_path}\")\n",
    "print(f\"Final dataset dimensions: {df_final.shape}\")\n",
    "print(f\"Columns exported: {list(df_final.columns)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
